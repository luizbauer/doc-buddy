"""
This module provides an implementation of the AIProvider interface using the Vertex AI API.
"""

import json
import os
import sys
import vertexai
from vertexai.preview.generative_models import (
    Content,
    Part,
    Tool,
    GenerativeModel,
    FunctionDeclaration,
)
from .ai_provider import AIProvider


class VertexAIProvider(AIProvider):
    """
    An AIProvider implementation that uses the Vertex AI API to generate content.
    """

    def __init__(self):
        required_env_vars = {
            "GOOGLE_VERTEXAI_PROJECT": "Google Cloud project ID",
            "GOOGLE_VERTEXAI_LOCATION": "Vertex AI location",
        }

        missing_vars = [var for var in required_env_vars if var not in os.environ]
        if missing_vars:
            raise ValueError(
                f"Missing required environment variables: "
                f"{', '.join(f'{var} ({required_env_vars[var]})' for var in missing_vars)}"
            )

        project_id = os.environ["GOOGLE_VERTEXAI_PROJECT"]
        region = os.environ["GOOGLE_VERTEXAI_LOCATION"]
        vertexai.init(project=project_id, location=region)

        if not hasattr(self, "_model"):
            self._model = ""

    def document_file(
        self, file_name, project_path, file_contents, notify_user_toast, tree
    ):
        """
        Documents a file using the Google Vertexai API by providing the file path,
        file name, and its contents.

        Args:
            file_name (str): The name of the file to document.
            project_path (str): The project path where the file is located.
            file_contents (str): The contents of the file to be documented.
            notify_user_toast (function): A function to notify the user with a toast message.
            tree (dict): The tree of the project.

        Returns:
            str: The generated documentation for the file.

        """
        from config import config

        if self._model is None or self._model == "":
            self._model = GenerativeModel(config.model)

        prompt = self.generate_prompt(file_name, project_path, file_contents, tree)

        messages = [
            Content(
                role="user",
                parts=[
                    Part.from_text(prompt),
                ],
            ),
        ]

        return self.get_completions(messages, notify_user_toast)

    def get_completions(self, messages, notify_user_toast):
        """
        Get completions for the given messages using the Google Vertexai API.

        Args:
            messages (list): A list of messages to generate completions for.
            notify_user_toast (function): A function to notify the user with a toast message.

        Returns:
            list: A list of completions generated by the AI model.

        """

        get_additional_file = FunctionDeclaration(
            name="get_additional_file",
            description="Retrieve the contents of an additional file required for documentation.",
            parameters={
                "type": "object",
                "properties": {
                    "file_path": {"type": "string"},
                },
                "required": ["file_path"],
            },
        )

        get_additional_file_tool = Tool(
            function_declarations=[get_additional_file],
        )

        while True:
            try:

                response = self._model.generate_content(
                    contents=messages,
                    tools=[get_additional_file_tool],
                )

                if response.candidates[0].content.parts[0].function_call is not None:
                    # one or more function calls

                    messages.append(response.candidates[0].content)
                    parts = response.candidates[0].content.parts

                    function_return_parts = []

                    for part in parts:
                        function_name = part.function_call.name

                        if function_name == "get_additional_file":
                            file_path = part.function_call.args["file_path"]

                            notify_user_toast(
                                f"LLM requested additional file: {file_path}"
                            )

                            additional_file_contents = self.retrieve_file_contents(
                                file_path
                            )

                            function_return_parts.append(
                                Part.from_function_response(
                                    name="get_additional_file",
                                    response={
                                        "content": {
                                            "contents": additional_file_contents
                                        }
                                    },
                                )
                            )

                        else:
                            sys.exit("Unknown function call")

                    messages.append(
                        Content(
                            role="function",
                            parts=function_return_parts,
                        ),
                    )

                else:
                    return response.candidates[0].content.parts[0].text

            except Exception as e:
                raise RuntimeError(f"Failed to generate documentation: {str(e)}") from e
